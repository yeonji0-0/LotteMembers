{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeonji0-0/PROJECT/blob/main/CD%EA%B3%BC%EC%A0%95%20%EB%94%A5%EB%9F%AC%EB%8B%9D/2_CNN_catdog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a10bc2ee",
      "metadata": {
        "id": "a10bc2ee"
      },
      "source": [
        "# CNN's with the Cats vs Dogs Dataset\n",
        "\n",
        "`Cats vs Dogs` 데이터 셋을 이용해서 개/고양이 구분하는 문제를 풀어보겠습니다.  \n",
        "Convolutional Neural Network 를 사용합니다.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d43abc49",
      "metadata": {
        "id": "d43abc49",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리들을 import  합니다.\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0000eebe",
      "metadata": {
        "id": "0000eebe"
      },
      "source": [
        "데이터 셋을 다운 받습니다.\n",
        "\n",
        "\n",
        "https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip 에서 파일을 다운 받도록 하겠습니다.  \n",
        "787MB 의 용량이니 다소 시간이 걸릴 수 있습니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dd9f52b",
      "metadata": {
        "id": "4dd9f52b"
      },
      "source": [
        "압축을 풀고 파일 경로를 맞춰줍니다. `./data/PetImages` 에 데이터를 위치하시면 아래 코드와 맞습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76034c9d",
      "metadata": {
        "id": "76034c9d",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "source_path = './data/PetImages'\n",
        "\n",
        "source_path_dogs = os.path.join(source_path, 'Dog')\n",
        "source_path_cats = os.path.join(source_path, 'Cat')\n",
        "\n",
        "# .db 파일들이 섞여 있기 때문에 지워 줍니다.\n",
        "import glob, os\n",
        "for f in glob.glob(\"./data/PetImages/*/*.db\"):\n",
        "    os.remove(f)\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_dogs))} images of dogs.\")\n",
        "print(f\"There are {len(os.listdir(source_path_cats))} images of cats.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b32b528",
      "metadata": {
        "id": "1b32b528"
      },
      "source": [
        "**예상 결과:**\n",
        "\n",
        "```\n",
        "There are 12500 images of dogs.\n",
        "There are 12500 images of cats.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6753b45c",
      "metadata": {
        "id": "6753b45c"
      },
      "source": [
        "Trainig 과 Validation 을 위해 데이터를 나눠 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e11c0fe",
      "metadata": {
        "id": "4e11c0fe"
      },
      "outputs": [],
      "source": [
        "root_dir = './data/cats-v-dogs'\n",
        "\n",
        "# 초기화 합니다.\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e6c840a",
      "metadata": {
        "cellView": "code",
        "id": "1e6c840a",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "def create_train_val_dirs(root_path):\n",
        "  # 디렉토리를 준비합니다.\n",
        "\n",
        "  os.mkdir(root_path)\n",
        "  train_dir = os.path.join(root_path, 'training')\n",
        "  os.mkdir(train_dir)\n",
        "  validation_dir = os.path.join(root_path, 'validation')\n",
        "  os.mkdir(validation_dir)\n",
        "\n",
        "  # 학습용 디렉토리\n",
        "  train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "  train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "  # 검증용 디렉토리\n",
        "  validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "  validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "  os.mkdir(train_cats_dir)\n",
        "  os.mkdir(train_dogs_dir)\n",
        "  os.mkdir(validation_cats_dir)\n",
        "  os.mkdir(validation_dogs_dir)\n",
        "\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  create_train_val_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"이미 존재함!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08f735fe",
      "metadata": {
        "id": "08f735fe",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# Test your create_train_val_dirs function\n",
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09e13d4e",
      "metadata": {
        "id": "09e13d4e"
      },
      "source": [
        "**예상 결과, 순서는 다를 수 있음:**\n",
        "\n",
        "``` txt\n",
        "./data/cats-v-dogs/training\n",
        "./data/cats-v-dogs/validation\n",
        "./data/cats-v-dogs/training/cats\n",
        "./data/cats-v-dogs/training/dogs\n",
        "./data/cats-v-dogs/validation/cats\n",
        "./data/cats-v-dogs/validation/dogs\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9413f4e5",
      "metadata": {
        "id": "9413f4e5"
      },
      "source": [
        " `split_data` 함수를 만들어 봅시다\n",
        "- SOURCE_DIR: 데이터 소스 경로\n",
        "\n",
        "- TRAINING_DIR: 학습 데이터 경로\n",
        "- VALIDATION_DIR: 검증 데이터 경로\n",
        "- SPLIT_SIZE: 나눌 데이터 사이즈\n",
        "\n",
        "이미지 파일들은 랜덤하게 나워져야만 합니다.\n",
        "\n",
        "예를 들어, `SOURCE_DIR` 이고 `PetImages/Cat`,  `SPLIT_SIZE` 가 .9 라면,\n",
        "`PetImages/Cat`에 있는 90% 의 이미지는 `TRAINING_DIR` 로 복사되어야 합니다.  \n",
        "나머지 10% 의 이미지는 `VALIDATION_DIR` 로 복사되어야 합니다.  \n",
        "\n",
        "모든 이미지는 복사되기 전에 빈 파일이 아닌지 체크해야합니다.  \n",
        "\n",
        "(참고)\n",
        "\n",
        "- `os.listdir(DIRECTORY)` returns a list with the contents of that directory.\n",
        "\n",
        "- `os.path.getsize(PATH)` returns the size of the file\n",
        "\n",
        "- `copyfile(source, destination)` copies a file from source to destination\n",
        "\n",
        "- `random.sample(list, len(list))` shuffles a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1c123a7",
      "metadata": {
        "cellView": "code",
        "id": "e1c123a7",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "\n",
        "  files = [os.path.join(SOURCE_DIR, f) for f in os.listdir(SOURCE_DIR) if os.path.isfile(os.path.join(SOURCE_DIR, f))]\n",
        "  random.shuffle(files)\n",
        "\n",
        "  files = [file for file in files if os.path.getsize(file) != 0]\n",
        "\n",
        "  train_len = int(len(files)*SPLIT_SIZE)\n",
        "\n",
        "  train_files = files[:train_len]\n",
        "  validation_files = files[train_len:]\n",
        "\n",
        "  for file_path in train_files:\n",
        "      copyfile(file_path, os.path.join(TRAINING_DIR, os.path.basename(file_path))  )\n",
        "  for file_path in validation_files:\n",
        "      copyfile(file_path, os.path.join(VALIDATION_DIR, os.path.basename(file_path)))\n",
        "\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f488106",
      "metadata": {
        "id": "7f488106",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "CAT_SOURCE_DIR = \"./data/PetImages/Cat/\"\n",
        "DOG_SOURCE_DIR = \"./data/PetImages/Dog/\"\n",
        "\n",
        "TRAINING_DIR = \"./data/cats-v-dogs/training/\"\n",
        "VALIDATION_DIR = \"./data/cats-v-dogs/validation/\"\n",
        "\n",
        "TRAINING_CATS_DIR = os.path.join(TRAINING_DIR, \"cats/\")\n",
        "VALIDATION_CATS_DIR = os.path.join(VALIDATION_DIR, \"cats/\")\n",
        "\n",
        "TRAINING_DOGS_DIR = os.path.join(TRAINING_DIR, \"dogs/\")\n",
        "VALIDATION_DOGS_DIR = os.path.join(VALIDATION_DIR, \"dogs/\")\n",
        "\n",
        "\n",
        "if len(os.listdir(TRAINING_CATS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_CATS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_DOGS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_DOGS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_CATS_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_CATS_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_DOGS_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_DOGS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "\n",
        "split_size = .9\n",
        "\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, VALIDATION_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, VALIDATION_DOGS_DIR, split_size)\n",
        "\n",
        "print(f\"\\n\\nOriginal cat's directory has {len(os.listdir(CAT_SOURCE_DIR))} images\")\n",
        "print(f\"Original dog's directory has {len(os.listdir(DOG_SOURCE_DIR))} images\\n\")\n",
        "\n",
        "print(f\"There are {len(os.listdir(TRAINING_CATS_DIR))} images of cats for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_DOGS_DIR))} images of dogs for training\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_CATS_DIR))} images of cats for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_DOGS_DIR))} images of dogs for validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbb2aedc",
      "metadata": {
        "id": "dbb2aedc"
      },
      "source": [
        "**예상 결과:**\n",
        "\n",
        "```\n",
        "Original cat's directory has 12500 images\n",
        "Original dog's directory has 12500 images\n",
        "\n",
        "There are 11249 images of cats for training\n",
        "There are 11249 images of dogs for training\n",
        "There are 1250 images of cats for validation\n",
        "There are 1250 images of dogs for validation\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32a30ba6",
      "metadata": {
        "id": "32a30ba6"
      },
      "source": [
        "이제,  Keras의 `ImageDataGenerator` 를 사용할 준비가 되었습니다.  \n",
        "학습과 검증을 위한 이미지의 batch 를 만들어 봅시다.\n",
        "  \n",
        "\n",
        "중요한 점 중 하나는 이미지의 해상도가 각기 다르다는 점입니다.  \n",
        "다행히 `flow_from_directory` method 는 이미지를 같은 해상도로 만들어 줍니다.  \n",
        "`target_size` 사용하여 해상도를 맞춥니다.  \n",
        "\n",
        "\n",
        "**`target_size` 는 (150, 150) 으로 설정합니다**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24714cb2",
      "metadata": {
        "cellView": "code",
        "id": "24714cb2",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "\n",
        "  # rescale 을 이용해서 normalize 를 해줍니다. 0~1 범위로 설정합니다\n",
        "  train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "  # data를 준비합니다.\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=20,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "  validation_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=20,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(150, 150))\n",
        "  return train_generator, validation_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a13c894",
      "metadata": {
        "id": "0a13c894",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2992173c",
      "metadata": {
        "id": "2992173c"
      },
      "source": [
        "**예상 결과:**\n",
        "\n",
        "```\n",
        "Found 22498 images belonging to 2 classes.\n",
        "Found 2500 images belonging to 2 classes.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b01ac22",
      "metadata": {
        "id": "4b01ac22"
      },
      "source": [
        "모델의 정의합니다.\n",
        "\n",
        "Keras' `Sequential` model을 사용합니다\n",
        "\n",
        "`loss` 도 `class_mode` 에 맞게 설정합니다.\n",
        "\n",
        "**최소한 3개의 convolution layer 가 있어야 개/고양이를 잘 구분할 수 있습니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2141d195",
      "metadata": {
        "cellView": "code",
        "id": "2141d195",
        "lines_to_next_cell": 2,
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fe2ed9f",
      "metadata": {
        "id": "5fe2ed9f"
      },
      "source": [
        "학습 시작!\n",
        "\n",
        "**Note:** `UserWarning: Possibly corrupt EXIF data` 워닝은 무시하셔도 됩니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87cbef80",
      "metadata": {
        "id": "87cbef80",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80ccc14c",
      "metadata": {
        "id": "80ccc14c"
      },
      "source": [
        "학습이 완료되면 아래 코드를 이용해서 얼마나 잘 구분을 하는지 확인 할 수 있습니다..\n",
        "\n",
        "**Training accuracy 는 적어도 95%, validation accuracy 는 적어도 80%** 가 나와야 충분합니다.  \n",
        "다양한 옵션들을 사용하면 성능을 더 끌어올릴 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32146607",
      "metadata": {
        "id": "32146607",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99fb2188",
      "metadata": {
        "id": "99fb2188"
      },
      "source": [
        "# Overfitting 해결하기\n",
        "- Overfitting 에 대해 생각해 봅시다... ㅠㅠ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0d26c6f",
      "metadata": {
        "id": "d0d26c6f"
      },
      "source": [
        "Overfitting 은 여러가지 방법으로 해결할 수 있습니다.  \n",
        "범용적으로 가장 쉬운 해결책은 목표 성능에 도달하면 학습을 멈추는 것입니다.  \n",
        "Early Stopping 을 구현해봅시다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ef88968",
      "metadata": {
        "id": "2ef88968"
      },
      "outputs": [],
      "source": [
        "# Callback 을 정의합니다.\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # Check the loss\n",
        "        if(logs.get('accuracy') > 0.80):\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# 학습 중 epoch 마다 성능을 검사하고, 목표에 도달하면 멈춥니다.\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator,\n",
        "                    callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3288957c",
      "metadata": {
        "id": "3288957c"
      },
      "source": [
        "computer vision 분야에서쉬운 해결책 중 하나는 Data Augmentation 입니다.  \n",
        "Data Augmentation 은 overfitting 문제 뿐만 아니라, data 가 부족한 경우, underfitting 문제도 해결이 가능할 수 있습니다.  \n",
        "이 외에도, training 의 품질을 올릴 수 있습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6214ae90",
      "metadata": {
        "id": "6214ae90"
      },
      "outputs": [],
      "source": [
        "# Create new model\n",
        "model_for_aug = create_model()\n",
        "\n",
        "# This code has changed. Now instead of the ImageGenerator just rescaling\n",
        "# the image, we also rotate and do other operations\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        TRAINING_DIR,  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        VALIDATION_DIR,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "# Train the new model\n",
        "history_with_aug = model_for_aug.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb13c16b",
      "metadata": {
        "id": "eb13c16b"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history_with_aug.history['accuracy']\n",
        "val_acc=history_with_aug.history['val_accuracy']\n",
        "loss=history_with_aug.history['loss']\n",
        "val_loss=history_with_aug.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}